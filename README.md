üåä Benthic Megafauna AI DetectorA specialized UI for marine scientists to detect, count, and catalog seafloor megafauna from image surveys and ROV video footage.This application provides a "point-and-click" dashboard for your trained YOLOv8 models. It is designed for ecological research, allowing you to process large datasets without writing code, while providing real-time abundance statistics and standardized data exports.‚ú® FeaturesOS Agnostic: Runs natively on Windows, macOS, and Linux/WSL.Dual Media Support: Process folders containing both static images (.jpg, .png) and high-resolution videos (.mp4, .avi, .mov).Real-time Dashboard: Watch a live feed of detections and track cumulative species abundance as the batch processes.Scientific Export: Automatically generates a detailed detection_report.csv containing species names, confidence scores, and frame/coordinate metadata.Safe-Save Mode: Every run creates a new timestamped folder, ensuring you never accidentally overwrite previous survey results.üõ†Ô∏è Installation (Recommended: Conda)We recommend using Miniconda to manage the software. This keeps the AI libraries isolated so they don't interfere with your other computer applications.1. Prerequisite: Install MinicondaIf you don't have it, download and install the version for your OS:Download Miniconda here2. Download this ProjectClone the repository or download the ZIP and extract it to your preferred location (e.g., Desktop/Benthic_AI).3. Setup the EnvironmentOpen your terminal (Mac/Linux) or Anaconda Prompt (Windows), navigate to the folder, and run:# Create the specialized environment
conda env create -f environment.yml

# Activate the environment
conda activate benthic_env
üöÄ How to Launch the ToolEvery time you want to use the tool:Open your Terminal or Anaconda Prompt.Type:conda activate benthic_env
streamlit run app.py
The dashboard will automatically open in your default web browser.Windows Pro-Tip: You can double-click the Launch_Benthic_AI.bat file in the project folder to start the app instantly without typing any commands.üñ•Ô∏è Using the DashboardSelect Folders: Paste the path to your Input folder (raw data) and Output folder (where results go).Set Confidence: Adjust the slider to determine how strict the AI should be.Low (0.25): More likely to catch everything, but may have some false detections.High (0.50): Very strict; only logs detections it is "sure" about.Optimize Video: For faster video processing, increase the Frame Stride (e.g., to 5 or 10) to skip identical frames while the ROV is moving slowly.Click Start: Watch the live feed. Once complete, your data will be waiting in the output folder.üìä Understanding Your OutputInside your timestamped results folder (e.g., Run_2026-02-05_14-30), you will find:detection_report.csv: A master spreadsheet for your statistical analysis.Annotated Media: Copies of your input files with boxes and labels drawn around the detected megafauna.CSV Column Reference:ColumnDescriptionFileThe original image or video filename.TypeWhether the detection was in an Image or Video.SpeciesThe taxonomic class identified by the model.ConfidenceHow certain the AI is (0.0 to 1.0).Frame_IndexFor videos, the specific frame where the detection occurred.üìù Citation & ResearchIf you use this tool for your research, please ensure you cite both the Ultralytics YOLOv8 framework and your specific model training protocol.Questions? Reach out to the project maintainer or open an issue in this repository.
